{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Case study 2: The Sars-Cov2 model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb1612e5198cab85"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-07T21:12:52.622647Z",
     "start_time": "2023-11-07T21:12:52.539309Z"
    }
   },
   "outputs": [],
   "source": [
    "# from eliater.network_validation import conditional_independence_test_summary\n",
    "import pandas as pd\n",
    "from y0.dsl import Variable\n",
    "from y0.graph import NxMixedGraph\n",
    "from src.eliater.frontdoor_backdoor import sars_cov2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is case study 2 in Figure 6 in this paper: Eliater: an analytical workflow and open source implementation for causal query estimation in biomolecular networks."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b60ed63441c5411"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "graph = NxMixedGraph.from_str_edges(\n",
    "    directed=[\n",
    "        (\"SARS_COV2\", \"ACE2\"),\n",
    "        (\"ACE2\", \"Ang\"),\n",
    "        (\"Ang\", \"AGTR1\"),\n",
    "        (\"AGTR1\", \"ADAM17\"),\n",
    "        (\"ADAM17\", \"EGF\"),\n",
    "        (\"ADAM17\", \"TNF\"),\n",
    "        (\"ADAM17\", \"Sil6R\"),\n",
    "        (\"SARS_COV2\", \"PRR\"),\n",
    "        (\"PRR\", \"NFKB\"),\n",
    "        (\"EGFR\", \"NFKB\"),\n",
    "        (\"TNF\", \"NFKB\"),\n",
    "        (\"Sil6R\", \"IL6STAT3\"),\n",
    "        (\"Toci\", \"Sil6R\"),\n",
    "        (\"NFKB\", \"IL6AMP\"),\n",
    "        (\"IL6AMP\", \"cytok\"),\n",
    "        (\"IL6STAT3\", \"IL6AMP\"),\n",
    "        (\"EGF\", \"EGFR\"),\n",
    "        (\"Gefi\", \"EGFR\"),\n",
    "    ],\n",
    "    undirected=[\n",
    "        (\"SARS_COV2\", \"Ang\"),\n",
    "        (\"ADAM17\", \"Sil6R\"),\n",
    "        (\"PRR\", \"NFKB\"),\n",
    "        (\"EGF\", \"EGFR\"),\n",
    "        (\"EGFR\", \"TNF\"),\n",
    "        (\"EGFR\", \"IL6STAT3\"),\n",
    "    ],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T21:11:41.780656Z",
     "start_time": "2023-11-07T21:11:41.710874Z"
    }
   },
   "id": "7ab5d32c79b7bf2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We get the observational data below. However, the data is mixed type, where the exposure (EGFR) is binary and rest of the variables are continuous. Currently, the conditional independence tests in eliater does not support mixed type data. Hence we discretize the data only to use for step 1. Rest of the steps support this type of data, so we use the original data for those steps."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5f92410e9801798"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# get observational data\n",
    "data = sars_cov2.generate(num_samples=1000, seed=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T21:20:45.334095Z",
     "start_time": "2023-11-07T21:20:45.295348Z"
    }
   },
   "id": "eb3a23add3bc3914"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5. 3. 7. ... 4. 4. 5.]\n",
      " [6. 2. 8. ... 1. 1. 2.]\n",
      " [4. 5. 5. ... 4. 4. 6.]\n",
      " ...\n",
      " [4. 4. 6. ... 4. 3. 4.]\n",
      " [9. 0. 9. ... 5. 6. 8.]\n",
      " [4. 5. 6. ... 3. 4. 5.]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (1000, 16), indices imply (1000, 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 23\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(data_trans)\n\u001B[1;32m      7\u001B[0m column_names \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSARS_COV2\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      8\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mACE2\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      9\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAng\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     21\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIL6AMP\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     22\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcytok\u001B[39m\u001B[38;5;124m\"\u001B[39m,]\n\u001B[0;32m---> 23\u001B[0m obs_data_discrete \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_trans\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# summarize first few rows\u001B[39;00m\n",
      "File \u001B[0;32m~/GitHub/eliater/venv/lib/python3.11/site-packages/pandas/core/frame.py:785\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[0;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[1;32m    774\u001B[0m         mgr \u001B[38;5;241m=\u001B[39m dict_to_mgr(\n\u001B[1;32m    775\u001B[0m             \u001B[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001B[39;00m\n\u001B[1;32m    776\u001B[0m             \u001B[38;5;66;03m# attribute \"name\"\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    782\u001B[0m             copy\u001B[38;5;241m=\u001B[39m_copy,\n\u001B[1;32m    783\u001B[0m         )\n\u001B[1;32m    784\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 785\u001B[0m         mgr \u001B[38;5;241m=\u001B[39m \u001B[43mndarray_to_mgr\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    786\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    787\u001B[0m \u001B[43m            \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    788\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    789\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    790\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmanager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    792\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001B[39;00m\n\u001B[1;32m    795\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_list_like(data):\n",
      "File \u001B[0;32m~/GitHub/eliater/venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:336\u001B[0m, in \u001B[0;36mndarray_to_mgr\u001B[0;34m(values, index, columns, dtype, copy, typ)\u001B[0m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001B[39;00m\n\u001B[1;32m    332\u001B[0m index, columns \u001B[38;5;241m=\u001B[39m _get_axes(\n\u001B[1;32m    333\u001B[0m     values\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], values\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], index\u001B[38;5;241m=\u001B[39mindex, columns\u001B[38;5;241m=\u001B[39mcolumns\n\u001B[1;32m    334\u001B[0m )\n\u001B[0;32m--> 336\u001B[0m \u001B[43m_check_values_indices_shape_match\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    338\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typ \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    339\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(values\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mtype, \u001B[38;5;28mstr\u001B[39m):\n",
      "File \u001B[0;32m~/GitHub/eliater/venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:420\u001B[0m, in \u001B[0;36m_check_values_indices_shape_match\u001B[0;34m(values, index, columns)\u001B[0m\n\u001B[1;32m    418\u001B[0m passed \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m    419\u001B[0m implied \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mlen\u001B[39m(index), \u001B[38;5;28mlen\u001B[39m(columns))\n\u001B[0;32m--> 420\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShape of passed values is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpassed\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, indices imply \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mimplied\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Shape of passed values is (1000, 16), indices imply (1000, 0)"
     ]
    }
   ],
   "source": [
    "# discritize the data\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "# discretization transform the raw data\n",
    "kbins = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
    "data_trans = kbins.fit_transform(obs_data)\n",
    "print(data_trans)\n",
    "column_names = [\"SARS_COV2\",\n",
    "                \"ACE2\",\n",
    "                \"Ang\",\n",
    "                \"AGTR1\",\n",
    "                \"ADAM17\",\n",
    "                \"Toci\",\n",
    "                \"Sil6R\",\n",
    "                \"EGF\",\n",
    "                \"TNF\",\n",
    "                \"Gefi\",\n",
    "                \"EGFR\",\n",
    "                \"PRR\",\n",
    "                \"NFKB\",\n",
    "                \"IL6STAT3\",\n",
    "                \"IL6AMP\",\n",
    "                \"cytok\",]\n",
    "obs_data_discrete = pd.DataFrame(data_trans, columns = [])\n",
    "# summarize first few rows\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T00:43:08.819233Z",
     "start_time": "2023-11-04T00:43:07.114011Z"
    }
   },
   "id": "192c73399eb31e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Verify correctness of the network structure"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22de51a518ee7699"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#remove after branches are merged to main\n",
    "import logging\n",
    "from typing import Dict, Literal, Optional\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from y0.algorithm.falsification import get_graph_falsifications\n",
    "from y0.dsl import Variable\n",
    "from y0.graph import NxMixedGraph\n",
    "from y0.struct import get_conditional_independence_tests\n",
    "\n",
    "logging.basicConfig(format=\"%(message)s\", level=logging.DEBUG)\n",
    "\n",
    "\n",
    "__all__ = [\n",
    "    \"conditional_independence_test_summary\",\n",
    "    \"validate_test\",\n",
    "    \"get_state_space_map\",\n",
    "    \"is_data_discrete\",\n",
    "    \"is_data_continuous\",\n",
    "    \"CITest\",\n",
    "    \"choose_default_test\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_state_space_map(\n",
    "    data: pd.DataFrame, threshold: Optional[int] = 10\n",
    ") -> Dict[Variable, Literal[\"discrete\", \"continuous\"]]:\n",
    "    \"\"\"Get a dictionary from each variable to its type.\n",
    "\n",
    "    :param data: the observed data\n",
    "    :param threshold: The threshold for determining a column as discrete\n",
    "        based on the number of unique values\n",
    "    :return: the mapping from column name to its type\n",
    "    \"\"\"\n",
    "    column_values_unique_count = {\n",
    "        column_name: data[column_name].nunique() for column_name in data.columns\n",
    "    }\n",
    "    return {\n",
    "        Variable(column): \"discrete\"\n",
    "        if column_values_unique_count[column] <= threshold\n",
    "        else \"continuous\"\n",
    "        for column in data.columns\n",
    "    }\n",
    "\n",
    "\n",
    "def is_data_discrete(data: pd.DataFrame) -> bool:\n",
    "    \"\"\"Check if all the columns in the dataframe has discrete data.\n",
    "\n",
    "    :param data: observational data.\n",
    "    :return: True, if all the columns have discrete data, False, otherwise\n",
    "    \"\"\"\n",
    "    variable_types = set(get_state_space_map(data=data).values())\n",
    "    return variable_types == {\"discrete\"}\n",
    "\n",
    "\n",
    "def is_data_continuous(data: pd.DataFrame) -> bool:\n",
    "    \"\"\"Check if all the columns in the dataframe has continuous data.\n",
    "\n",
    "    :param data: observational.\n",
    "    :return: True, if all the columns have continuous data, False, otherwise\n",
    "    \"\"\"\n",
    "    variable_types = set(get_state_space_map(data).values())\n",
    "    return variable_types == {\"continuous\"}\n",
    "\n",
    "\n",
    "CITest = Literal[\n",
    "    \"pearson\",\n",
    "    \"chi-square\",\n",
    "    \"cressie_read\",\n",
    "    \"freeman_tuckey\",\n",
    "    \"g_sq\",\n",
    "    \"log_likelihood\",\n",
    "    \"modified_log_likelihood\",\n",
    "    \"power_divergence\",\n",
    "    \"neyman\",\n",
    "]\n",
    "\n",
    "\n",
    "def choose_default_test(data: pd.DataFrame) -> CITest:\n",
    "    \"\"\"Choose the default statistical test for testing conditional independencies based on the data.\n",
    "\n",
    "    :param data: observational data.\n",
    "    :return: the default test based on data\n",
    "    :raises NotImplementedError: if data is of mixed type (contains both discrete and continuous columns)\n",
    "    \"\"\"\n",
    "    if is_data_discrete(data):\n",
    "        return \"chi-square\"\n",
    "    if is_data_continuous(data):\n",
    "        return \"pearson\"\n",
    "    raise NotImplementedError(\n",
    "        \"Mixed data types are not allowed. Either all of the columns of data should be discrete / continuous.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def validate_test(\n",
    "    data: pd.DataFrame,\n",
    "    test: Optional[CITest],\n",
    ") -> None:\n",
    "    \"\"\"Validate the conditional independency test passed by the user.\n",
    "\n",
    "    :param data: observational data.\n",
    "    :param test: the conditional independency test passed by the user.\n",
    "    :raises ValueError: if the passed test is invalid / unsupported, pearson is used for discrete data or\n",
    "        chi-square is used for continuous data\n",
    "    \"\"\"\n",
    "    tests = get_conditional_independence_tests()\n",
    "    if test not in tests:\n",
    "        raise ValueError(f\"`{test}` is invalid. Supported CI tests are: {sorted(tests)}\")\n",
    "\n",
    "    if is_data_continuous(data) and test != \"pearson\":\n",
    "        raise ValueError(\n",
    "            \"The data is continuous. Either discretize and use chi-square or use the pearson.\"\n",
    "        )\n",
    "\n",
    "    if is_data_discrete(data) and test == \"pearson\":\n",
    "        raise ValueError(\"Cannot run pearson on discrete data. Use chi-square instead.\")\n",
    "\n",
    "\n",
    "def conditional_independence_test_summary(\n",
    "    graph: NxMixedGraph,\n",
    "    data: pd.DataFrame,\n",
    "    test: Optional[CITest] = None,\n",
    "    significance_level: Optional[float] = None,\n",
    "    verbose: Optional[bool] = False,\n",
    ") -> None:\n",
    "    \"\"\"Print the summary of conditional independency test results.\n",
    "\n",
    "    Prints the summary to the console, which includes the total number of conditional independence tests,\n",
    "    the number and percentage of failed tests, and statistical information about each test such as p-values,\n",
    "    and test results.\n",
    "\n",
    "    :param graph: an NxMixedGraph\n",
    "    :param data: observational data corresponding to the graph\n",
    "    :param test: the conditional independency test to use. If None, defaults to ``pearson`` for continuous data\n",
    "        and ``chi-square`` for discrete data.\n",
    "    :param significance_level: The statistical tests employ this value for\n",
    "        comparison with the p-value of the test to determine the independence of\n",
    "        the tested variables. If none, defaults to 0.01.\n",
    "    :param verbose: If `False`, only print the details of failed tests.\n",
    "        If 'True', print the details of all the conditional independency results. Defaults to `False`\n",
    "    :raises NotImplementedError: if data is of mixed type (contains both discrete and continuous columns)\n",
    "    \"\"\"\n",
    "    if significance_level is None:\n",
    "        significance_level = 0.01\n",
    "    if not test:\n",
    "        test = choose_default_test(data)\n",
    "    else:\n",
    "        # Validate test and data\n",
    "        validate_test(data=data, test=test)\n",
    "        if len(set(get_state_space_map(data).values())) > 1:\n",
    "            raise NotImplementedError(\n",
    "                \"Mixed data types are not allowed. Either all of the columns of data should be discrete / continuous.\"\n",
    "            )\n",
    "    test_results = get_graph_falsifications(\n",
    "        graph=graph, df=data, method=test, significance_level=significance_level\n",
    "    ).evidence\n",
    "    # Find the result based on p-value\n",
    "    test_results[\"result\"] = test_results[\"p\"].apply(\n",
    "        lambda p_value: \"fail\" if p_value < significance_level else \"pass\"\n",
    "    )\n",
    "    # Selecting columns of interest\n",
    "    test_results = test_results[[\"left\", \"right\", \"given\", \"p\", \"result\"]]\n",
    "    # Sorting the rows by index\n",
    "    test_results = test_results.sort_index()\n",
    "    test_results = test_results.rename(columns={\"p\": \"p-value\"})\n",
    "    failed_tests = test_results[test_results[\"result\"] == \"fail\"]\n",
    "    total_no_of_tests = len(test_results)\n",
    "    total_no_of_failed_tests = len(failed_tests)\n",
    "    percentage_of_failed_tests = total_no_of_failed_tests / total_no_of_tests * 100\n",
    "    logging.info(\"Total number of conditional independencies: \" + str(total_no_of_tests))\n",
    "    logging.info(\"Total number of failed tests: \" + str(total_no_of_failed_tests))\n",
    "    logging.info(\"Percentage of failed tests: \" + str(percentage_of_failed_tests))\n",
    "    if verbose:\n",
    "        logging.info(test_results.to_string(index=False))\n",
    "    else:\n",
    "        logging.info(failed_tests.to_string(index=False))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T19:56:15.906408Z",
     "start_time": "2023-11-03T19:56:15.892527Z"
    }
   },
   "id": "defeb7abb5b64dbd"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mconditional_independence_test_summary\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobs_data_discrete\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[20], line 147\u001B[0m, in \u001B[0;36mconditional_independence_test_summary\u001B[0;34m(graph, data, test, significance_level, verbose)\u001B[0m\n\u001B[1;32m    145\u001B[0m     significance_level \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.01\u001B[39m\n\u001B[1;32m    146\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m test:\n\u001B[0;32m--> 147\u001B[0m     test \u001B[38;5;241m=\u001B[39m \u001B[43mchoose_default_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    149\u001B[0m     \u001B[38;5;66;03m# Validate test and data\u001B[39;00m\n\u001B[1;32m    150\u001B[0m     validate_test(data\u001B[38;5;241m=\u001B[39mdata, test\u001B[38;5;241m=\u001B[39mtest)\n",
      "Cell \u001B[0;32mIn[20], line 87\u001B[0m, in \u001B[0;36mchoose_default_test\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mchoose_default_test\u001B[39m(data: pd\u001B[38;5;241m.\u001B[39mDataFrame) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m CITest:\n\u001B[1;32m     81\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Choose the default statistical test for testing conditional independencies based on the data.\u001B[39;00m\n\u001B[1;32m     82\u001B[0m \n\u001B[1;32m     83\u001B[0m \u001B[38;5;124;03m    :param data: observational data.\u001B[39;00m\n\u001B[1;32m     84\u001B[0m \u001B[38;5;124;03m    :return: the default test based on data\u001B[39;00m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;124;03m    :raises NotImplementedError: if data is of mixed type (contains both discrete and continuous columns)\u001B[39;00m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 87\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mis_data_discrete\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m     88\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchi-square\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     89\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_data_continuous(data):\n",
      "Cell \u001B[0;32mIn[20], line 53\u001B[0m, in \u001B[0;36mis_data_discrete\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mis_data_discrete\u001B[39m(data: pd\u001B[38;5;241m.\u001B[39mDataFrame) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n\u001B[1;32m     48\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Check if all the columns in the dataframe has discrete data.\u001B[39;00m\n\u001B[1;32m     49\u001B[0m \n\u001B[1;32m     50\u001B[0m \u001B[38;5;124;03m    :param data: observational data.\u001B[39;00m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;124;03m    :return: True, if all the columns have discrete data, False, otherwise\u001B[39;00m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 53\u001B[0m     variable_types \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(\u001B[43mget_state_space_map\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mvalues())\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m variable_types \u001B[38;5;241m==\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdiscrete\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n",
      "Cell \u001B[0;32mIn[20], line 37\u001B[0m, in \u001B[0;36mget_state_space_map\u001B[0;34m(data, threshold)\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_state_space_map\u001B[39m(\n\u001B[1;32m     27\u001B[0m     data: pd\u001B[38;5;241m.\u001B[39mDataFrame, threshold: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[1;32m     28\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[Variable, Literal[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdiscrete\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontinuous\u001B[39m\u001B[38;5;124m\"\u001B[39m]]:\n\u001B[1;32m     29\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get a dictionary from each variable to its type.\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \n\u001B[1;32m     31\u001B[0m \u001B[38;5;124;03m    :param data: the observed data\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;124;03m    :return: the mapping from column name to its type\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m     36\u001B[0m     column_values_unique_count \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m---> 37\u001B[0m         column_name: data[column_name]\u001B[38;5;241m.\u001B[39mnunique() \u001B[38;5;28;01mfor\u001B[39;00m column_name \u001B[38;5;129;01min\u001B[39;00m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\n\u001B[1;32m     38\u001B[0m     }\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[1;32m     40\u001B[0m         Variable(column): \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdiscrete\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     41\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m column_values_unique_count[column] \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m threshold\n\u001B[1;32m     42\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontinuous\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m column \u001B[38;5;129;01min\u001B[39;00m data\u001B[38;5;241m.\u001B[39mcolumns\n\u001B[1;32m     44\u001B[0m     }\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "conditional_independence_test_summary(graph=graph, data=obs_data_discrete, verbose=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T20:01:59.820360Z",
     "start_time": "2023-11-03T20:01:59.697495Z"
    }
   },
   "id": "e21efcf3940ffc5e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Check query identifiability"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "944520ca55c79b4b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Identification(outcomes=\"{cytok}, treatments=\"{EGFR}\",conditions=\"set()\",  graph=\"NxMixedGraph(directed=<networkx.classes.digraph.DiGraph object at 0x1161e49d0>, undirected=<networkx.classes.graph.Graph object at 0x1161e7890>)\", estimand=\"P(ACE2, ADAM17, AGTR1, Ang, EGF, EGFR, Gefi, IL6AMP, IL6STAT3, NFKB, PRR, SARS_COV2, Sil6r, TNF, Toci, cytok)\")"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from y0.algorithm.identify import Identification\n",
    "from y0.dsl import P\n",
    "id_in = Identification.from_expression(\n",
    "    query=P(Variable('cytok') @ Variable('EGFR')),\n",
    "    graph=graph,\n",
    ")\n",
    "id_in"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T21:12:59.613121Z",
     "start_time": "2023-11-07T21:12:59.577683Z"
    }
   },
   "id": "25bb329cbc5a1e08"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The query is identifiable."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ac9e0aec8791fbc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Find nuisance variables and mark them as latent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e84ccc3bdc28f772"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#remove after merging simplify branch to main\n",
    "import itertools\n",
    "from typing import Iterable, Optional, Set, Union\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from y0.algorithm.simplify_latent import simplify_latent_dag\n",
    "from y0.dsl import Variable\n",
    "from y0.graph import DEFAULT_TAG, NxMixedGraph\n",
    "\n",
    "__all__ = [\n",
    "    \"remove_latent_variables\",\n",
    "    \"mark_nuisance_variables_as_latent\",\n",
    "    \"find_all_nodes_in_causal_paths\",\n",
    "    \"find_nuisance_variables\",\n",
    "]\n",
    "\n",
    "\n",
    "def remove_latent_variables(\n",
    "    graph: NxMixedGraph,\n",
    "    treatments: Union[Variable, Set[Variable]],\n",
    "    outcomes: Union[Variable, Set[Variable]],\n",
    "    tag: Optional[str] = None,\n",
    ") -> NxMixedGraph:\n",
    "    \"\"\"Find all nuissance variables and remove them based on Evans' simplification rules.\n",
    "\n",
    "    :param graph: an NxMixedGraph\n",
    "    :param treatments: a list of treatments\n",
    "    :param outcomes: a list of outcomes\n",
    "    :param tag: The tag for which variables are latent\n",
    "    :return: the new graph after simplification\n",
    "    \"\"\"\n",
    "    lv_dag = mark_nuisance_variables_as_latent(\n",
    "        graph=graph, treatments=treatments, outcomes=outcomes, tag=tag\n",
    "    )\n",
    "    simplified_latent_dag = simplify_latent_dag(lv_dag, tag=tag)\n",
    "    return NxMixedGraph.from_latent_variable_dag(simplified_latent_dag.graph, tag=tag)\n",
    "\n",
    "\n",
    "def mark_nuisance_variables_as_latent(\n",
    "    graph: NxMixedGraph,\n",
    "    treatments: Union[Variable, Set[Variable]],\n",
    "    outcomes: Union[Variable, Set[Variable]],\n",
    "    tag: Optional[str] = None,\n",
    ") -> nx.DiGraph:\n",
    "    \"\"\"Find all the nuisance variables and mark them as latent.\n",
    "\n",
    "    Mark nuisance variables as latent by first identifying them, then creating a new graph where these\n",
    "    nodes are marked as latent. Nuisance variables are the descendants of nodes in all proper causal paths\n",
    "    that are not ancestors of the outcome variables nodes. A proper causal path is a directed path from\n",
    "    treatments to the outcome. Nuisance variables should not be included in the estimation of the causal\n",
    "    effect as they increase the variance.\n",
    "\n",
    "    :param graph: an NxMixedGraph\n",
    "    :param treatments: a list of treatments\n",
    "    :param outcomes: a list of outcomes\n",
    "    :param tag: The tag for which variables are latent\n",
    "    :return: the modified graph after simplification, in place\n",
    "    \"\"\"\n",
    "    if tag is None:\n",
    "        tag = DEFAULT_TAG\n",
    "    nuisance_variables = find_nuisance_variables(graph, treatments=treatments, outcomes=outcomes)\n",
    "    lv_dag = NxMixedGraph.to_latent_variable_dag(graph, tag=tag)\n",
    "    # Set nuisance variables as latent\n",
    "    for node, data in lv_dag.nodes(data=True):\n",
    "        if Variable(node) in nuisance_variables:\n",
    "            data[tag] = True\n",
    "    return lv_dag\n",
    "\n",
    "\n",
    "def find_all_nodes_in_causal_paths(\n",
    "    graph: NxMixedGraph,\n",
    "    treatments: Union[Variable, Set[Variable]],\n",
    "    outcomes: Union[Variable, Set[Variable]],\n",
    ") -> Set[Variable]:\n",
    "    \"\"\"Find all the nodes in proper causal paths from treatments to outcomes.\n",
    "\n",
    "    A proper causal path is a directed path from treatments to the outcome.\n",
    "\n",
    "    :param graph: an NxMixedGraph\n",
    "    :param treatments: a list of treatments\n",
    "    :param outcomes: a list of outcomes\n",
    "    :return: the nodes on all causal paths from treatments to outcomes.\n",
    "    \"\"\"\n",
    "    if isinstance(treatments, Variable):\n",
    "        treatments = {treatments}\n",
    "    if isinstance(outcomes, Variable):\n",
    "        outcomes = {outcomes}\n",
    "\n",
    "    return {\n",
    "        node\n",
    "        for treatment, outcome in itertools.product(treatments, outcomes)\n",
    "        for causal_path in nx.all_simple_paths(graph.directed, treatment, outcome)\n",
    "        for node in causal_path\n",
    "    }\n",
    "\n",
    "\n",
    "def find_nuisance_variables(\n",
    "    graph: NxMixedGraph,\n",
    "    treatments: Union[Variable, Set[Variable]],\n",
    "    outcomes: Union[Variable, Set[Variable]],\n",
    ") -> Iterable[Variable]:\n",
    "    \"\"\"Find the nuisance variables in the graph.\n",
    "\n",
    "    Nuisance variables are the descendants of nodes in all proper causal paths that are\n",
    "    not ancestors of the outcome variables' nodes. A proper causal path is a directed path\n",
    "    from treatments to the outcome. Nuisance variables should not be included in the estimation\n",
    "    of the causal effect as they increase the variance.\n",
    "\n",
    "    :param graph: an NxMixedGraph\n",
    "    :param treatments: a list of treatments\n",
    "    :param outcomes: a list of outcomes\n",
    "    :returns: The nuisance variables.\n",
    "    \"\"\"\n",
    "    if isinstance(treatments, Variable):\n",
    "        treatments = {treatments}\n",
    "    if isinstance(outcomes, Variable):\n",
    "        outcomes = {outcomes}\n",
    "\n",
    "    # Find the nodes on all causal paths\n",
    "    nodes_on_causal_paths = find_all_nodes_in_causal_paths(\n",
    "        graph=graph, treatments=treatments, outcomes=outcomes\n",
    "    )\n",
    "\n",
    "    # Find the descendants of interest\n",
    "    descendants_of_nodes_on_causal_paths = graph.descendants_inclusive(nodes_on_causal_paths)\n",
    "\n",
    "    # Find the ancestors of outcome variables\n",
    "    ancestors_of_outcomes = graph.ancestors_inclusive(outcomes)\n",
    "\n",
    "    descendants_not_ancestors = descendants_of_nodes_on_causal_paths.difference(\n",
    "        ancestors_of_outcomes\n",
    "    )\n",
    "\n",
    "    nuisance_variables = descendants_not_ancestors.difference(treatments.union(outcomes))\n",
    "    return nuisance_variables"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T21:13:07.057132Z",
     "start_time": "2023-11-07T21:13:06.988025Z"
    }
   },
   "id": "fa27799f0ee4008"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function finds the nuisance variables for the input graph."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7ea93588b4f7188"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "set()"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuisance_variables = find_nuisance_variables(graph, treatments=Variable(\"EGFR\"), outcomes=Variable(\"cytok\"))\n",
    "nuisance_variables"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T21:13:10.613534Z",
     "start_time": "2023-11-07T21:13:10.576759Z"
    }
   },
   "id": "4dff38fbf23ce61c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "No variable is identified as the nuisance variable. Hence the simplified network in the next step will produce a graph similar to the original graph."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7401dd4e2c6d5d31"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Simplify the network"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6aa2819509255d89"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following function find the nuisance variable (step 3), marks them as latent and then applies Evan's simplification rules to remove the nuisance variables. As there are no nuisance variables, the new graph will be the same as the original graph."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b987190a5fa7453"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "new_graph = remove_latent_variables(graph, treatments=Variable(\"EGFR\"), outcomes=Variable(\"cytok\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T21:13:16.787411Z",
     "start_time": "2023-11-07T21:13:16.767118Z"
    }
   },
   "id": "e6849ec627ee2b59"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5: Estimate the query"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8e9dd961d1d459a"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#remove after estimation branch is merged to main\n",
    "#pip install ananke-causal"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T21:13:21.906535Z",
     "start_time": "2023-11-07T21:13:21.869132Z"
    }
   },
   "id": "55dad0af00a5d2d6"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#remove after estimation branch is merged to main and replace with eliater codes\n",
    "from ananke.graphs import ADMG\n",
    "from ananke.identification import OneLineID\n",
    "from ananke.estimation import CausalEffect\n",
    "from ananke.datasets import load_afixable_data\n",
    "from ananke.estimation import AutomatedIF\n",
    "from ananke import identification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ananke.models import LinearGaussianSEM\n",
    "import warnings\n",
    "import numpy\n",
    "import random\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T21:13:33.533482Z",
     "start_time": "2023-11-07T21:13:25.015917Z"
    }
   },
   "id": "626b65a84d854261"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Treatment is a-fixable.\n",
      "\n",
      " Available estimators are :\n",
      " \n",
      "1. IPW (ipw)\n",
      "2. Outcome regression (gformula)\n",
      "3. Generalized AIPW (aipw)\n",
      " \n",
      "Suggested estimator is Generalized AIPW \n"
     ]
    },
    {
     "data": {
      "text/plain": "<ananke.estimation.counterfactual_mean.CausalEffect at 0x126c197d0>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove after estimation branch is merged to main\n",
    "vertices = ['SARS_COV2', 'ACE2','Ang','AGTR1',\n",
    "            'ADAM17','Toci','Sil6R','EGF',\n",
    "            'TNF','EGFR','PRR','NFKB',\n",
    "            'IL6STAT3','IL6AMP','cytok','Gefi']\n",
    "di_edges = [('SARS_COV2','ACE2'),\n",
    "            ('ACE2','Ang'),\n",
    "            ('Ang','AGTR1'),\n",
    "            ('AGTR1','ADAM17'),\n",
    "            ('ADAM17','EGF'),\n",
    "            ('ADAM17','TNF'),\n",
    "            ('ADAM17','Sil6R'),\n",
    "            ('SARS_COV2','PRR'),\n",
    "            ('PRR','NFKB'),\n",
    "            ('EGFR','NFKB'),\n",
    "            ('TNF','NFKB'),\n",
    "            ('Sil6R','IL6STAT3'),\n",
    "            ('Toci','Sil6R'),\n",
    "            ('NFKB','IL6AMP'),\n",
    "            ('IL6AMP','cytok'),\n",
    "            ('IL6STAT3','IL6AMP'),\n",
    "            ('EGF','EGFR'), \n",
    "            ('Gefi', 'EGFR')]\n",
    "bi_edges = [(\"SARS_COV2\", \"Ang\"),\n",
    "            (\"ADAM17\", \"Sil6R\"),\n",
    "            (\"PRR\", \"NFKB\"),\n",
    "            (\"EGF\", \"EGFR\"),\n",
    "            (\"EGFR\", \"TNF\"),\n",
    "            (\"EGFR\", \"IL6STAT3\")]\n",
    "new_graph = ADMG(vertices, di_edges, bi_edges)\n",
    "\n",
    "ate_obj = CausalEffect(graph=new_graph, treatment='EGFR', outcome='cytok')  # setting up the CausalEffect object\n",
    "ate_obj"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T21:22:51.387565Z",
     "start_time": "2023-11-07T21:22:51.122934Z"
    }
   },
   "id": "2591c0454078d610"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "0.40458569285087265"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove after estimation branch is merged to main and use eliater function\n",
    "#Estimated ATE\n",
    "ate_obj.compute_effect(data, \"aipw\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T21:22:55.162195Z",
     "start_time": "2023-11-07T21:22:54.712134Z"
    }
   },
   "id": "849166896befe315"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7961491870724515"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the real value of ATE\n",
    "intv_data1 = sars_cov2.generate(num_samples=1000, treatments={Variable('EGFR'):1}, seed=1)\n",
    "intv_data0 = sars_cov2.generate(num_samples=1000, treatments={Variable('EGFR'):0}, seed=1)\n",
    "np.mean(intv_data1['cytok']) - np.mean(intv_data0['cytok'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T21:25:47.887959Z",
     "start_time": "2023-11-07T21:25:47.836561Z"
    }
   },
   "id": "caea998d59f12fa8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8da8ac5fe1baa878"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
