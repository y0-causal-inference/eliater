{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Motivating example: Figure 4"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abc410d51568d48c"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-20T13:49:49.773667Z",
     "start_time": "2023-11-20T13:49:49.673200Z"
    }
   },
   "outputs": [],
   "source": [
    "#from eliater.network_validation import conditional_independence_test_summary\n",
    "\n",
    "# from src.eliater.frontdoor_backdoor_discrete import (\n",
    "#     single_mediator_with_multiple_confounders_nuisances_discrete_example,\n",
    "# )\n",
    "\n",
    "from y0.graph import NxMixedGraph\n",
    "from y0.dsl import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is the motivating example in Figure 4 (a) in this paper: *Eliater: an analytical workflow and open source implementation for causal query\n",
    "estimation in biomolecular networks*. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bda3042434f63a26"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "graph = NxMixedGraph.from_str_edges(\n",
    "    directed=[\n",
    "        (\"Z1\", \"X\"),\n",
    "        (\"Z1\", \"Z2\"),\n",
    "        (\"Z2\", \"Z3\"),\n",
    "        (\"Z3\", \"Y\"),\n",
    "        (\"X\", \"M1\"),\n",
    "        (\"M1\", \"Y\"),\n",
    "        (\"M1\", \"R1\"),\n",
    "        (\"R1\", \"R2\"),\n",
    "        (\"R2\", \"R3\"),\n",
    "        (\"Y\", \"R3\"),\n",
    "    ],\n",
    "    undirected=[\n",
    "        # (\"Z1\", \"X\"),\n",
    "    ],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T13:49:51.515840Z",
     "start_time": "2023-11-20T13:49:51.475580Z"
    }
   },
   "id": "5805a9bed9191161"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "#remove after CI branch is merged\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from y0.algorithm.identify import Query\n",
    "from y0.dsl import Z1, Z2, Z3, Variable, X, Y\n",
    "from y0.examples import Example\n",
    "\n",
    "M1 = Variable(\"M1\")\n",
    "R1 = Variable(\"R1\")\n",
    "R2 = Variable(\"R2\")\n",
    "R3 = Variable(\"R3\")\n",
    "\n",
    "__all__ = [\n",
    "    \"single_mediator_with_multiple_confounders_nuisances_discrete_example\",\n",
    "]\n",
    "\n",
    "\n",
    "def _r_exp(x):\n",
    "    return 1 / (1 + np.exp(x))\n",
    "\n",
    "\n",
    "def generate(\n",
    "    num_samples: int = 1000,\n",
    "    treatments: dict[Variable, float] | None = None,\n",
    "    *,\n",
    "    seed: int | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Generate discrete testing data for the multiple_mediators_with_multiple_confounders_nuisances_discrete case study.\n",
    "\n",
    "    :param num_samples: The number of samples to generate. Try 1000.\n",
    "    :param treatments: An optional dictionary of the values to fix each variable to.\n",
    "    :param seed: An optional random seed for reproducibility purposes\n",
    "    :returns: A pandas Dataframe with columns corresponding\n",
    "        to the variable names in the multiple_mediators_with_multiple_confounders_nuisances_discrete example\n",
    "    \"\"\"\n",
    "    if treatments is None:\n",
    "        treatments = {}\n",
    "    generator = np.random.default_rng(seed)\n",
    "\n",
    "    values_z1 = [0, 1]\n",
    "    probs_z1 = [0.4, 0.6]\n",
    "\n",
    "    if Z1 in treatments:\n",
    "        z1 = np.full(num_samples, treatments[Z1])\n",
    "    else:\n",
    "        z1 = generator.choice(values_z1, num_samples, p=probs_z1)\n",
    "\n",
    "    beta0_z2 = 1\n",
    "    beta_z1_to_z2 = 0.3\n",
    "\n",
    "    if Z2 in treatments:\n",
    "        z2 = np.full(num_samples, treatments[Z2])\n",
    "    else:\n",
    "        probs_z2 = _r_exp(-beta0_z2 - z1 * beta_z1_to_z2)\n",
    "        z2 = generator.binomial(n=1, p=probs_z2, size=num_samples)\n",
    "\n",
    "    beta0_z3 = 1.2\n",
    "    beta_z2_to_z3 = 0.6\n",
    "\n",
    "    if Z3 in treatments:\n",
    "        z3 = np.full(num_samples, treatments[Z3])\n",
    "    else:\n",
    "        probs_z3 = _r_exp(-beta0_z3 - z2 * beta_z2_to_z3)\n",
    "        z3 = generator.binomial(n=1, p=probs_z3, size=num_samples)\n",
    "\n",
    "    beta0_x = 1\n",
    "    beta_z1_to_x = 0.6\n",
    "\n",
    "    if X in treatments:\n",
    "        x = np.full(num_samples, treatments[X])\n",
    "    else:\n",
    "        probs_x = _r_exp(-beta0_x - z1 * beta_z1_to_x)\n",
    "        x = generator.binomial(n=1, p=probs_x, size=num_samples)\n",
    "\n",
    "    beta0_m1 = 1\n",
    "    beta_x_to_m1 = 0.7\n",
    "\n",
    "    if M1 in treatments:\n",
    "        m1 = np.full(num_samples, treatments[M1])\n",
    "    else:\n",
    "        probs_m1 = _r_exp(-beta0_m1 - x * beta_x_to_m1)\n",
    "        m1 = generator.binomial(n=1, p=probs_m1, size=num_samples)\n",
    "\n",
    "    beta0_y = 1.8\n",
    "    beta_z3_to_y = 0.5\n",
    "    beta_m1_to_y = 0.7\n",
    "    if Y in treatments:\n",
    "        y = np.full(num_samples, treatments[Y])\n",
    "    else:\n",
    "        probs_y = _r_exp(-beta0_y - z3 * beta_z3_to_y - m1 * beta_m1_to_y)\n",
    "        y = generator.binomial(n=1, p=probs_y, size=num_samples)\n",
    "\n",
    "    beta0_r1 = 1.5\n",
    "    beta_m1_to_r1 = 0.7\n",
    "\n",
    "    if R1 in treatments:\n",
    "        r1 = np.full(num_samples, treatments[R1])\n",
    "    else:\n",
    "        probs_r1 = _r_exp(-beta0_r1 - m1 * beta_m1_to_r1)\n",
    "        r1 = generator.binomial(n=1, p=probs_r1, size=num_samples)\n",
    "\n",
    "    beta0_r2 = 1.4\n",
    "    beta_r1_to_r2 = 0.4\n",
    "\n",
    "    if R2 in treatments:\n",
    "        r2 = np.full(num_samples, treatments[R2])\n",
    "    else:\n",
    "        probs_r2 = _r_exp(-beta0_r2 - r1 * beta_r1_to_r2)\n",
    "        r2 = generator.binomial(n=1, p=probs_r2, size=num_samples)\n",
    "\n",
    "    beta0_r3 = 1.1\n",
    "    beta_r2_to_r3 = 0.3\n",
    "    beta_y_to_r3 = 0.3\n",
    "\n",
    "    if R3 in treatments:\n",
    "        r3 = np.full(num_samples, treatments[R3])\n",
    "    else:\n",
    "        probs_r3 = _r_exp(-beta0_r3 - r2 * beta_r2_to_r3 - y * beta_y_to_r3)\n",
    "        r3 = generator.binomial(n=1, p=probs_r3, size=num_samples)\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            X.name: x,\n",
    "            M1.name: m1,\n",
    "            Z1.name: z1,\n",
    "            Z2.name: z2,\n",
    "            Z3.name: z3,\n",
    "            R1.name: r1,\n",
    "            R2.name: r2,\n",
    "            R3.name: r3,\n",
    "            Y.name: y,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "single_mediator_with_multiple_confounders_nuisances_discrete_example = Example(\n",
    "    name=\"frontdoor with multiple mediators, confounders and nuisance variables\",\n",
    "    reference=\"Causal workflow paper, figure 4 (a).\",\n",
    "    description=\"This is an extension of the frontdoor_backdoor example from y0 module\"\n",
    "    \" but with more variables directly connecting the treatment to outcome (mediators)\"\n",
    "    \"and several additional variables that are a direct cause of both the treatment and outcome\"\n",
    "    \"(confounders), and several nuisance variables. The nuisance variables are R1, R2, R3. \"\n",
    "    \"They should not be part of query estimation because they are downstream of the outcome.\"\n",
    "    \" In the data generation process, all the variables are discrete. This \"\n",
    "    \"example is designed to check if the conditional independencies implied by the graph are\"\n",
    "    \" aligned with the ones implied by the data via the X-square test.\",\n",
    "    graph=graph,\n",
    "    generate_data=generate,\n",
    "    example_queries=[Query.from_str(treatments=\"X\", outcomes=\"Y\")],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T13:49:53.621252Z",
     "start_time": "2023-11-20T13:49:53.540009Z"
    }
   },
   "id": "7eeab9a801c51106"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "     X  M1  Z1  Z2  Z3  R1  R2  R3  Y\n0    1   1   1   1   1   1   1   1  1\n1    0   1   1   1   0   1   0   1  1\n2    1   1   0   1   1   1   1   1  1\n3    1   1   1   1   1   1   1   0  1\n4    1   1   0   1   1   0   0   1  1\n..  ..  ..  ..  ..  ..  ..  ..  .. ..\n495  1   1   1   1   0   1   1   1  1\n496  1   1   1   0   0   1   1   1  0\n497  1   1   0   1   1   1   1   1  1\n498  1   1   1   0   1   1   1   1  1\n499  1   1   1   0   1   0   1   1  1\n\n[500 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X</th>\n      <th>M1</th>\n      <th>Z1</th>\n      <th>Z2</th>\n      <th>Z3</th>\n      <th>R1</th>\n      <th>R2</th>\n      <th>R3</th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = single_mediator_with_multiple_confounders_nuisances_discrete_example.generate_data(num_samples=500, seed=1)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T13:50:00.262386Z",
     "start_time": "2023-11-20T13:50:00.140694Z"
    }
   },
   "id": "24a3d8b93b3804f2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Verify correctness of the network structure"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f8b8c77d0b42c3e"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#remove after branch is merged\n",
    "import logging\n",
    "from typing import Dict, Literal, Optional\n",
    "import pandas as pd\n",
    "\n",
    "from y0.algorithm.falsification import get_graph_falsifications\n",
    "from y0.dsl import Variable\n",
    "from y0.graph import NxMixedGraph\n",
    "from y0.struct import get_conditional_independence_tests\n",
    "\n",
    "logging.basicConfig(format=\"%(message)s\", level=logging.DEBUG)\n",
    "\n",
    "\n",
    "__all__ = [\n",
    "    \"conditional_independence_test_summary\",\n",
    "    \"validate_test\",\n",
    "    \"get_state_space_map\",\n",
    "    \"is_data_discrete\",\n",
    "    \"is_data_continuous\",\n",
    "    \"CITest\",\n",
    "    \"choose_default_test\",\n",
    "]\n",
    "\n",
    "TESTS = get_conditional_independence_tests()\n",
    "\n",
    "\n",
    "def get_state_space_map(\n",
    "    data: pd.DataFrame, threshold: Optional[int] = 10\n",
    ") -> Dict[Variable, Literal[\"discrete\", \"continuous\"]]:\n",
    "    \"\"\"Get a dictionary from each variable to its type.\n",
    "\n",
    "    :param data: the observed data\n",
    "    :param threshold: The threshold for determining a column as discrete\n",
    "        based on the number of unique values\n",
    "    :return: the mapping from column name to its type\n",
    "    \"\"\"\n",
    "    column_values_unique_count = {\n",
    "        column_name: data[column_name].nunique() for column_name in data.columns\n",
    "    }\n",
    "    return {\n",
    "        Variable(column): \"discrete\"\n",
    "        if column_values_unique_count[column] <= threshold\n",
    "        else \"continuous\"\n",
    "        for column in data.columns\n",
    "    }\n",
    "\n",
    "\n",
    "def is_data_discrete(data: pd.DataFrame) -> bool:\n",
    "    \"\"\"Check if all the columns in the dataframe has discrete data.\n",
    "\n",
    "    :param data: observational data.\n",
    "    :return: True, if all the columns have discrete data, False, otherwise\n",
    "    \"\"\"\n",
    "    variable_types = set(get_state_space_map(data=data).values())\n",
    "    return variable_types == {\"discrete\"}\n",
    "\n",
    "\n",
    "def is_data_continuous(data: pd.DataFrame) -> bool:\n",
    "    \"\"\"Check if all the columns in the dataframe has continuous data.\n",
    "\n",
    "    :param data: observational.\n",
    "    :return: True, if all the columns have continuous data, False, otherwise\n",
    "    \"\"\"\n",
    "    variable_types = set(get_state_space_map(data).values())\n",
    "    return variable_types == {\"continuous\"}\n",
    "\n",
    "\n",
    "# TODO replace with y0.struct.CITest\n",
    "CITest = Literal[\n",
    "    \"pearson\",\n",
    "    \"chi-square\",\n",
    "    \"cressie_read\",\n",
    "    \"freeman_tuckey\",\n",
    "    \"g_sq\",\n",
    "    \"log_likelihood\",\n",
    "    \"modified_log_likelihood\",\n",
    "    \"power_divergence\",\n",
    "    \"neyman\",\n",
    "]\n",
    "\n",
    "\n",
    "def choose_default_test(data: pd.DataFrame) -> CITest:\n",
    "    \"\"\"Choose the default statistical test for testing conditional independencies based on the data.\n",
    "\n",
    "    :param data: observational data.\n",
    "    :return: the default test based on data\n",
    "    :raises NotImplementedError: if data is of mixed type (contains both discrete and continuous columns)\n",
    "    \"\"\"\n",
    "    if is_data_discrete(data):\n",
    "        return \"chi-square\"\n",
    "    if is_data_continuous(data):\n",
    "        return \"pearson\"\n",
    "    raise NotImplementedError(\n",
    "        \"Mixed data types are not allowed. Either all of the columns of data should be discrete / continuous.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def validate_test(\n",
    "    data: pd.DataFrame,\n",
    "    test: Optional[CITest],\n",
    ") -> None:\n",
    "    \"\"\"Validate the conditional independency test passed by the user.\n",
    "\n",
    "    :param data: observational data.\n",
    "    :param test: the conditional independency test passed by the user.\n",
    "    :raises ValueError: if the passed test is invalid / unsupported, pearson is used for discrete data or\n",
    "        chi-square is used for continuous data\n",
    "    \"\"\"\n",
    "    tests = get_conditional_independence_tests()\n",
    "    if test not in tests:\n",
    "        raise ValueError(f\"`{test}` is invalid. Supported CI tests are: {sorted(tests)}\")\n",
    "\n",
    "    if is_data_continuous(data) and test != \"pearson\":\n",
    "        raise ValueError(\n",
    "            \"The data is continuous. Either discretize and use chi-square or use the pearson.\"\n",
    "        )\n",
    "\n",
    "    if is_data_discrete(data) and test == \"pearson\":\n",
    "        raise ValueError(\"Cannot run pearson on discrete data. Use chi-square instead.\")\n",
    "\n",
    "\n",
    "def conditional_independence_test_summary(\n",
    "    graph: NxMixedGraph,\n",
    "    data: pd.DataFrame,\n",
    "    test: Optional[CITest] = None,\n",
    "    max_given: Optional[int] = 5,\n",
    "    significance_level: Optional[float] = None,\n",
    "    verbose: Optional[bool] = False,\n",
    ") -> None:\n",
    "    \"\"\"Print the summary of conditional independency test results.\n",
    "\n",
    "    Prints the summary to the console, which includes the total number of conditional independence tests,\n",
    "    the number and percentage of failed tests, and statistical information about each test such as p-values,\n",
    "    and test results.\n",
    "\n",
    "    :param graph: an NxMixedGraph\n",
    "    :param data: observational data corresponding to the graph\n",
    "    :param test: the conditional independency test to use. If None, defaults to ``pearson`` for continuous data\n",
    "        and ``chi-square`` for discrete data.\n",
    "    :param max_given: The maximum set size in the power set of the vertices minus the d-separable pairs\n",
    "    :param significance_level: The statistical tests employ this value for\n",
    "        comparison with the p-value of the test to determine the independence of\n",
    "        the tested variables. If none, defaults to 0.01.\n",
    "    :param verbose: If `False`, only print the details of failed tests.\n",
    "        If 'True', print the details of all the conditional independency results. Defaults to `False`\n",
    "    :raises NotImplementedError: if data is of mixed type (contains both discrete and continuous columns)\n",
    "    \"\"\"\n",
    "    if significance_level is None:\n",
    "        significance_level = 0.01\n",
    "    if not test:\n",
    "        test = choose_default_test(data)\n",
    "    else:\n",
    "        # Validate test and data\n",
    "        validate_test(data=data, test=test)\n",
    "        if len(set(get_state_space_map(data).values())) > 1:\n",
    "            raise NotImplementedError(\n",
    "                \"Mixed data types are not allowed. Either all of the columns of data should be discrete / continuous.\"\n",
    "            )\n",
    "    test_results = get_graph_falsifications(\n",
    "        graph=graph,\n",
    "        df=data,\n",
    "        method=test,\n",
    "        significance_level=significance_level,\n",
    "        max_given=max_given,\n",
    "    ).evidence\n",
    "    # Find the result based on p-value\n",
    "    test_results[\"result\"] = test_results[\"p\"].apply(\n",
    "        lambda p_value: \"fail\" if p_value < significance_level else \"pass\"\n",
    "    )\n",
    "    # Selecting columns of interest\n",
    "    test_results = test_results[[\"left\", \"right\", \"given\", \"p\", \"result\"]]\n",
    "    # Sorting the rows by index\n",
    "    test_results = test_results.sort_index()\n",
    "    test_results = test_results.rename(columns={\"p\": \"p-value\"})\n",
    "    failed_tests = test_results[test_results[\"result\"] == \"fail\"]\n",
    "    total_no_of_tests = len(test_results)\n",
    "    total_no_of_failed_tests = len(failed_tests)\n",
    "    percentage_of_failed_tests = total_no_of_failed_tests / total_no_of_tests\n",
    "    logging.info(f\"Total number of conditional independencies: {total_no_of_tests:,}\")\n",
    "    logging.info(f\"Total number of failed tests: {total_no_of_failed_tests:,}\")\n",
    "    logging.info(f\"Percentage of failed tests: {percentage_of_failed_tests:.2%}\")\n",
    "    if verbose:\n",
    "        logging.info(test_results.to_string(index=False))\n",
    "    else:\n",
    "        logging.info(failed_tests.to_string(index=False))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T15:58:19.308237Z",
     "start_time": "2023-11-16T15:58:04.012646Z"
    }
   },
   "id": "651f4a6f2802c61e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "Total number of conditional independencies: 26\n",
      "Total number of failed tests: 0\n",
      "Percentage of failed tests: 0.00%\n",
      "left right given  p-value result\n",
      "  R2    Z2    R1 0.925150   pass\n",
      "   X     Y M1|Z1 0.915287   pass\n",
      "  M1    Z2     X 0.238941   pass\n",
      "  M1    R2    R1 0.184011   pass\n",
      "  R1    Z2    M1 0.962174   pass\n",
      "  R3     X  R1|Y 0.415925   pass\n",
      "   X    Z2    Z1 0.998180   pass\n",
      "  M1    Z3     X 1.000000   pass\n",
      "  R2    Z3    R1 0.146435   pass\n",
      "  M1    Z1     X 0.601740   pass\n",
      "   Y    Z1 M1|Z2 1.000000   pass\n",
      "  R3    Z1  M1|Y 0.853116   pass\n",
      "  R1    Z1    M1 0.089977   pass\n",
      "  R3    Z2  R1|Y 0.872744   pass\n",
      "  R2    Z1    M1 0.528383   pass\n",
      "   X    Z3    Z1 0.372179   pass\n",
      "  R2     X    R1 0.807598   pass\n",
      "  R1    Z3    M1 0.914470   pass\n",
      "  R1    R3 M1|R2 0.932222   pass\n",
      "  R2     Y    R1 1.000000   pass\n",
      "   Y    Z2 M1|Z3 0.908691   pass\n",
      "  R1     X    M1 0.843317   pass\n",
      "  Z1    Z3    Z2 0.834617   pass\n",
      "  M1    R3  R1|Y 0.570586   pass\n",
      "  R1     Y    M1 0.555707   pass\n",
      "  R3    Z3  R1|Y 0.932276   pass\n"
     ]
    }
   ],
   "source": [
    "conditional_independence_test_summary(graph, data, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T14:35:54.984517Z",
     "start_time": "2023-11-09T14:35:53.289736Z"
    }
   },
   "id": "4e3220a2c48cb9b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "All the d-separations implied by the network are validated by the data. No test failed. Hence, we can proceed to step 2."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b40df88c10664e3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Check query identifiability"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4435aa5f3a8f55b9"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Identification(outcomes=\"{Y}, treatments=\"{X}\",conditions=\"set()\",  graph=\"NxMixedGraph(directed=<networkx.classes.digraph.DiGraph object at 0x118041e10>, undirected=<networkx.classes.graph.Graph object at 0x118040550>)\", estimand=\"P(M1, R1, R2, R3, X, Y, Z1, Z2, Z3)\")"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from y0.algorithm.identify import Identification\n",
    "from y0.dsl import P\n",
    "id_in = Identification.from_expression(\n",
    "    query=P(Variable('Y') @ Variable('X')),\n",
    "    graph=graph,\n",
    ")\n",
    "id_in"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T14:36:07.528585Z",
     "start_time": "2023-11-09T14:36:07.491893Z"
    }
   },
   "id": "6a1d0da707ca1d2f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The query is identifiable. Hence we can proceed to step 3."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e27342ad3164b42"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Find nuisance variables and mark them as latent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ed3073afbc7030a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#remove after merging simplify branch to main\n",
    "import itertools\n",
    "from typing import Iterable, Optional, Set, Union\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from y0.algorithm.simplify_latent import simplify_latent_dag\n",
    "from y0.dsl import Variable\n",
    "from y0.graph import DEFAULT_TAG, NxMixedGraph\n",
    "\n",
    "__all__ = [\n",
    "    \"remove_latent_variables\",\n",
    "    \"mark_nuisance_variables_as_latent\",\n",
    "    \"find_all_nodes_in_causal_paths\",\n",
    "    \"find_nuisance_variables\",\n",
    "]\n",
    "\n",
    "\n",
    "def remove_latent_variables(\n",
    "    graph: NxMixedGraph,\n",
    "    treatments: Union[Variable, Set[Variable]],\n",
    "    outcomes: Union[Variable, Set[Variable]],\n",
    "    tag: Optional[str] = None,\n",
    ") -> NxMixedGraph:\n",
    "    \"\"\"Find all nuissance variables and remove them based on Evans' simplification rules.\n",
    "\n",
    "    :param graph: an NxMixedGraph\n",
    "    :param treatments: a list of treatments\n",
    "    :param outcomes: a list of outcomes\n",
    "    :param tag: The tag for which variables are latent\n",
    "    :return: the new graph after simplification\n",
    "    \"\"\"\n",
    "    lv_dag = mark_nuisance_variables_as_latent(\n",
    "        graph=graph, treatments=treatments, outcomes=outcomes, tag=tag\n",
    "    )\n",
    "    simplified_latent_dag = simplify_latent_dag(lv_dag, tag=tag)\n",
    "    return NxMixedGraph.from_latent_variable_dag(simplified_latent_dag.graph, tag=tag)\n",
    "\n",
    "\n",
    "def mark_nuisance_variables_as_latent(\n",
    "    graph: NxMixedGraph,\n",
    "    treatments: Union[Variable, Set[Variable]],\n",
    "    outcomes: Union[Variable, Set[Variable]],\n",
    "    tag: Optional[str] = None,\n",
    ") -> nx.DiGraph:\n",
    "    \"\"\"Find all the nuisance variables and mark them as latent.\n",
    "\n",
    "    Mark nuisance variables as latent by first identifying them, then creating a new graph where these\n",
    "    nodes are marked as latent. Nuisance variables are the descendants of nodes in all proper causal paths\n",
    "    that are not ancestors of the outcome variables nodes. A proper causal path is a directed path from\n",
    "    treatments to the outcome. Nuisance variables should not be included in the estimation of the causal\n",
    "    effect as they increase the variance.\n",
    "\n",
    "    :param graph: an NxMixedGraph\n",
    "    :param treatments: a list of treatments\n",
    "    :param outcomes: a list of outcomes\n",
    "    :param tag: The tag for which variables are latent\n",
    "    :return: the modified graph after simplification, in place\n",
    "    \"\"\"\n",
    "    if tag is None:\n",
    "        tag = DEFAULT_TAG\n",
    "    nuisance_variables = find_nuisance_variables(graph, treatments=treatments, outcomes=outcomes)\n",
    "    lv_dag = NxMixedGraph.to_latent_variable_dag(graph, tag=tag)\n",
    "    # Set nuisance variables as latent\n",
    "    for node, data in lv_dag.nodes(data=True):\n",
    "        if Variable(node) in nuisance_variables:\n",
    "            data[tag] = True\n",
    "    return lv_dag\n",
    "\n",
    "\n",
    "def find_all_nodes_in_causal_paths(\n",
    "    graph: NxMixedGraph,\n",
    "    treatments: Union[Variable, Set[Variable]],\n",
    "    outcomes: Union[Variable, Set[Variable]],\n",
    ") -> Set[Variable]:\n",
    "    \"\"\"Find all the nodes in proper causal paths from treatments to outcomes.\n",
    "\n",
    "    A proper causal path is a directed path from treatments to the outcome.\n",
    "\n",
    "    :param graph: an NxMixedGraph\n",
    "    :param treatments: a list of treatments\n",
    "    :param outcomes: a list of outcomes\n",
    "    :return: the nodes on all causal paths from treatments to outcomes.\n",
    "    \"\"\"\n",
    "    if isinstance(treatments, Variable):\n",
    "        treatments = {treatments}\n",
    "    if isinstance(outcomes, Variable):\n",
    "        outcomes = {outcomes}\n",
    "\n",
    "    return {\n",
    "        node\n",
    "        for treatment, outcome in itertools.product(treatments, outcomes)\n",
    "        for causal_path in nx.all_simple_paths(graph.directed, treatment, outcome)\n",
    "        for node in causal_path\n",
    "    }\n",
    "\n",
    "\n",
    "def find_nuisance_variables(\n",
    "    graph: NxMixedGraph,\n",
    "    treatments: Union[Variable, Set[Variable]],\n",
    "    outcomes: Union[Variable, Set[Variable]],\n",
    ") -> Iterable[Variable]:\n",
    "    \"\"\"Find the nuisance variables in the graph.\n",
    "\n",
    "    Nuisance variables are the descendants of nodes in all proper causal paths that are\n",
    "    not ancestors of the outcome variables' nodes. A proper causal path is a directed path\n",
    "    from treatments to the outcome. Nuisance variables should not be included in the estimation\n",
    "    of the causal effect as they increase the variance.\n",
    "\n",
    "    :param graph: an NxMixedGraph\n",
    "    :param treatments: a list of treatments\n",
    "    :param outcomes: a list of outcomes\n",
    "    :returns: The nuisance variables.\n",
    "    \"\"\"\n",
    "    if isinstance(treatments, Variable):\n",
    "        treatments = {treatments}\n",
    "    if isinstance(outcomes, Variable):\n",
    "        outcomes = {outcomes}\n",
    "\n",
    "    # Find the nodes on all causal paths\n",
    "    nodes_on_causal_paths = find_all_nodes_in_causal_paths(\n",
    "        graph=graph, treatments=treatments, outcomes=outcomes\n",
    "    )\n",
    "\n",
    "    # Find the descendants of interest\n",
    "    descendants_of_nodes_on_causal_paths = graph.descendants_inclusive(nodes_on_causal_paths)\n",
    "\n",
    "    # Find the ancestors of outcome variables\n",
    "    ancestors_of_outcomes = graph.ancestors_inclusive(outcomes)\n",
    "\n",
    "    descendants_not_ancestors = descendants_of_nodes_on_causal_paths.difference(\n",
    "        ancestors_of_outcomes\n",
    "    )\n",
    "\n",
    "    nuisance_variables = descendants_not_ancestors.difference(treatments.union(outcomes))\n",
    "    return nuisance_variables"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T14:36:17.956888Z",
     "start_time": "2023-11-09T14:36:17.898354Z"
    }
   },
   "id": "f33b609ae0013a3b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function finds the nuisance variables for the input graph."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7661cedf357ad01"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{R1, R2, R3}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuisance_variables = find_nuisance_variables(graph, treatments=Variable(\"X\"), outcomes=Variable(\"Y\"))\n",
    "nuisance_variables"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T14:36:19.488645Z",
     "start_time": "2023-11-09T14:36:19.390596Z"
    }
   },
   "id": "c094ba6186dfecf6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The nuisance variables are $R_1$, $R_2$, and $R_3$."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79a36765bb1640f6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Simplify the network"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b86a9300fa3d3881"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following function find the nuisance variable (step 3), marks them as latent and then applies Evan's simplification rules to remove the nuisance variables. The new graph does not contain nuisance variables."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92e386966d986cec"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "new_graph = remove_latent_variables(graph, treatments=Variable(\"X\"), outcomes=Variable(\"Y\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T14:36:26.339397Z",
     "start_time": "2023-11-09T14:36:26.316945Z"
    }
   },
   "id": "e1d0f93c0d993112"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5: Estimate the query"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1b8adaf922f3096"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from y0.algorithm.estimation import estimate_ace"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T15:59:30.695790Z",
     "start_time": "2023-11-16T15:59:30.573586Z"
    }
   },
   "id": "9544bf2cd9459cc"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/ananke/estimation/counterfactual_mean.py:1127: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for colname, colvalues in df.iteritems():\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n",
      "SG\n",
      "ADMG\n"
     ]
    },
    {
     "data": {
      "text/plain": "-0.6949811379122186"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATE_value = estimate_ace(graph=graph,\n",
    "                         treatments=Variable(\"Raf\"),\n",
    "                         outcomes=Variable(\"Erk\"),\n",
    "                         data=data)\n",
    "ATE_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T16:02:08.586705Z",
     "start_time": "2023-11-16T16:02:06.827300Z"
    }
   },
   "id": "55a147fe3a3ee98d"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#remove after estimation branch is merged to main\n",
    "#pip install ananke-causal"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T14:36:27.799919Z",
     "start_time": "2023-11-09T14:36:27.771415Z"
    }
   },
   "id": "df8232aa72e3628f"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0040000000000000036"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the real value of ATE\n",
    "intv_data1 = single_mediator_with_multiple_confounders_nuisances_discrete_example.generate_data(num_samples=500, treatments={Variable('X'):1}, seed=1)\n",
    "intv_data0 = single_mediator_with_multiple_confounders_nuisances_discrete_example.generate_data(num_samples=500, treatments={Variable('X'):0}, seed=1)\n",
    "np.mean(intv_data1['Y']) - np.mean(intv_data0['Y'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T14:36:56.691146Z",
     "start_time": "2023-11-09T14:36:56.507662Z"
    }
   },
   "id": "c9193b27bbbd5d30"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
