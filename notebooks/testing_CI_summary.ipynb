{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#remove after branch is merged\n",
    "import logging\n",
    "from typing import Dict, Literal, Optional\n",
    "import pandas as pd\n",
    "\n",
    "from y0.algorithm.falsification import get_graph_falsifications\n",
    "from y0.dsl import Variable\n",
    "from y0.graph import NxMixedGraph\n",
    "from y0.struct import get_conditional_independence_tests\n",
    "\n",
    "logging.basicConfig(format=\"%(message)s\", level=logging.DEBUG)\n",
    "\n",
    "\n",
    "__all__ = [\n",
    "    \"conditional_independence_test_summary\",\n",
    "    \"validate_test\",\n",
    "    \"get_state_space_map\",\n",
    "    \"is_data_discrete\",\n",
    "    \"is_data_continuous\",\n",
    "    \"CITest\",\n",
    "    \"choose_default_test\",\n",
    "]\n",
    "\n",
    "TESTS = get_conditional_independence_tests()\n",
    "\n",
    "\n",
    "def get_state_space_map(\n",
    "    data: pd.DataFrame, threshold: Optional[int] = 10\n",
    ") -> Dict[Variable, Literal[\"discrete\", \"continuous\"]]:\n",
    "    \"\"\"Get a dictionary from each variable to its type.\n",
    "\n",
    "    :param data: the observed data\n",
    "    :param threshold: The threshold for determining a column as discrete\n",
    "        based on the number of unique values\n",
    "    :return: the mapping from column name to its type\n",
    "    \"\"\"\n",
    "    column_values_unique_count = {\n",
    "        column_name: data[column_name].nunique() for column_name in data.columns\n",
    "    }\n",
    "    return {\n",
    "        Variable(column): \"discrete\"\n",
    "        if column_values_unique_count[column] <= threshold\n",
    "        else \"continuous\"\n",
    "        for column in data.columns\n",
    "    }\n",
    "\n",
    "\n",
    "def is_data_discrete(data: pd.DataFrame) -> bool:\n",
    "    \"\"\"Check if all the columns in the dataframe has discrete data.\n",
    "\n",
    "    :param data: observational data.\n",
    "    :return: True, if all the columns have discrete data, False, otherwise\n",
    "    \"\"\"\n",
    "    variable_types = set(get_state_space_map(data=data).values())\n",
    "    return variable_types == {\"discrete\"}\n",
    "\n",
    "\n",
    "def is_data_continuous(data: pd.DataFrame) -> bool:\n",
    "    \"\"\"Check if all the columns in the dataframe has continuous data.\n",
    "\n",
    "    :param data: observational.\n",
    "    :return: True, if all the columns have continuous data, False, otherwise\n",
    "    \"\"\"\n",
    "    variable_types = set(get_state_space_map(data).values())\n",
    "    return variable_types == {\"continuous\"}\n",
    "\n",
    "\n",
    "# TODO replace with y0.struct.CITest\n",
    "CITest = Literal[\n",
    "    \"pearson\",\n",
    "    \"chi-square\",\n",
    "    \"cressie_read\",\n",
    "    \"freeman_tuckey\",\n",
    "    \"g_sq\",\n",
    "    \"log_likelihood\",\n",
    "    \"modified_log_likelihood\",\n",
    "    \"power_divergence\",\n",
    "    \"neyman\",\n",
    "]\n",
    "\n",
    "\n",
    "def choose_default_test(data: pd.DataFrame) -> CITest:\n",
    "    \"\"\"Choose the default statistical test for testing conditional independencies based on the data.\n",
    "\n",
    "    :param data: observational data.\n",
    "    :return: the default test based on data\n",
    "    :raises NotImplementedError: if data is of mixed type (contains both discrete and continuous columns)\n",
    "    \"\"\"\n",
    "    if is_data_discrete(data):\n",
    "        return \"chi-square\"\n",
    "    if is_data_continuous(data):\n",
    "        return \"pearson\"\n",
    "    raise NotImplementedError(\n",
    "        \"Mixed data types are not allowed. Either all of the columns of data should be discrete / continuous.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def validate_test(\n",
    "    data: pd.DataFrame,\n",
    "    test: Optional[CITest],\n",
    ") -> None:\n",
    "    \"\"\"Validate the conditional independency test passed by the user.\n",
    "\n",
    "    :param data: observational data.\n",
    "    :param test: the conditional independency test passed by the user.\n",
    "    :raises ValueError: if the passed test is invalid / unsupported, pearson is used for discrete data or\n",
    "        chi-square is used for continuous data\n",
    "    \"\"\"\n",
    "    tests = get_conditional_independence_tests()\n",
    "    if test not in tests:\n",
    "        raise ValueError(f\"`{test}` is invalid. Supported CI tests are: {sorted(tests)}\")\n",
    "\n",
    "    if is_data_continuous(data) and test != \"pearson\":\n",
    "        raise ValueError(\n",
    "            \"The data is continuous. Either discretize and use chi-square or use the pearson.\"\n",
    "        )\n",
    "\n",
    "    if is_data_discrete(data) and test == \"pearson\":\n",
    "        raise ValueError(\"Cannot run pearson on discrete data. Use chi-square instead.\")\n",
    "\n",
    "\n",
    "def conditional_independence_test_summary(\n",
    "    graph: NxMixedGraph,\n",
    "    data: pd.DataFrame,\n",
    "    test: Optional[CITest] = None,\n",
    "    significance_level: Optional[float] = None,\n",
    "    verbose: Optional[bool] = False,\n",
    ") -> None:\n",
    "    \"\"\"Print the summary of conditional independency test results.\n",
    "\n",
    "    Prints the summary to the console, which includes the total number of conditional independence tests,\n",
    "    the number and percentage of failed tests, and statistical information about each test such as p-values,\n",
    "    and test results.\n",
    "\n",
    "    :param graph: an NxMixedGraph\n",
    "    :param data: observational data corresponding to the graph\n",
    "    :param test: the conditional independency test to use. If None, defaults to ``pearson`` for continuous data\n",
    "        and ``chi-square`` for discrete data.\n",
    "    :param significance_level: The statistical tests employ this value for\n",
    "        comparison with the p-value of the test to determine the independence of\n",
    "        the tested variables. If none, defaults to 0.01.\n",
    "    :param verbose: If `False`, only print the details of failed tests.\n",
    "        If 'True', print the details of all the conditional independency results. Defaults to `False`\n",
    "    :raises NotImplementedError: if data is of mixed type (contains both discrete and continuous columns)\n",
    "    \"\"\"\n",
    "    if significance_level is None:\n",
    "        significance_level = 0.01\n",
    "    if not test:\n",
    "        test = choose_default_test(data)\n",
    "    else:\n",
    "        # Validate test and data\n",
    "        validate_test(data=data, test=test)\n",
    "        if len(set(get_state_space_map(data).values())) > 1:\n",
    "            raise NotImplementedError(\n",
    "                \"Mixed data types are not allowed. Either all of the columns of data should be discrete / continuous.\"\n",
    "            )\n",
    "    test_results = get_graph_falsifications(\n",
    "        graph=graph, df=data, method=test, significance_level=significance_level\n",
    "    ).evidence\n",
    "    # Find the result based on p-value\n",
    "    test_results[\"result\"] = test_results[\"p\"].apply(\n",
    "        lambda p_value: \"fail\" if p_value < significance_level else \"pass\"\n",
    "    )\n",
    "    # Selecting columns of interest\n",
    "    test_results = test_results[[\"left\", \"right\", \"given\", \"p\", \"result\"]]\n",
    "    # Sorting the rows by index\n",
    "    test_results = test_results.sort_index()\n",
    "    test_results = test_results.rename(columns={\"p\": \"p-value\"})\n",
    "    failed_tests = test_results[test_results[\"result\"] == \"fail\"]\n",
    "    total_no_of_tests = len(test_results)\n",
    "    total_no_of_failed_tests = len(failed_tests)\n",
    "    percentage_of_failed_tests = total_no_of_failed_tests / total_no_of_tests\n",
    "    logging.info(f\"Total number of conditional independencies: {total_no_of_tests:,}\")\n",
    "    logging.info(f\"Total number of failed tests: {total_no_of_failed_tests:,}\")\n",
    "    logging.info(f\"Percentage of failed tests: {percentage_of_failed_tests:.2%}\")\n",
    "    if verbose:\n",
    "        logging.info(test_results.to_string(index=False))\n",
    "    else:\n",
    "        logging.info(failed_tests.to_string(index=False))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T15:33:26.317132Z",
     "start_time": "2023-11-08T15:33:25.245603Z"
    }
   },
   "id": "c665fbe493915dc8"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n"
     ]
    },
    {
     "data": {
      "text/plain": "  left right given  chi^2   p  dof  Holmâ€“Bonferroni level  flagged\n0   M2     X    M1    0.0 NaN    0               0.003333    False\n1   M1     Y  M2|X    0.0 NaN    0               0.005000    False",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>left</th>\n      <th>right</th>\n      <th>given</th>\n      <th>chi^2</th>\n      <th>p</th>\n      <th>dof</th>\n      <th>Holmâ€“Bonferroni level</th>\n      <th>flagged</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M2</td>\n      <td>X</td>\n      <td>M1</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.003333</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M1</td>\n      <td>Y</td>\n      <td>M2|X</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.005000</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    test_results = get_graph_falsifications(\n",
    "        graph=graph, df=data, method=\"pearson\", significance_level=0.01\n",
    "    ).evidence\n",
    "    test_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T14:08:17.520645Z",
     "start_time": "2023-11-08T14:08:11.866906Z"
    }
   },
   "id": "7f60508a96ff7590"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Example 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9575a6ce4dc23b3e"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from y0.algorithm.identify import Query\n",
    "from y0.dsl import Variable, X, Y\n",
    "from y0.examples import Example\n",
    "from y0.graph import NxMixedGraph\n",
    "\n",
    "M1 = Variable(\"M1\")\n",
    "M2 = Variable(\"M2\")\n",
    "R1 = Variable(\"R1\")\n",
    "R2 = Variable(\"R2\")\n",
    "R3 = Variable(\"R3\")\n",
    "\n",
    "\n",
    "graph = NxMixedGraph.from_edges(\n",
    "    directed=[\n",
    "        (X, M1),\n",
    "        (M1, M2),\n",
    "        (M2, Y),\n",
    "    ],\n",
    "    undirected=[\n",
    "        (X, Y),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "def generate(\n",
    "    num_samples: int = 1000,\n",
    "    treatments: dict[Variable, float] | None = None,\n",
    "    *,\n",
    "    seed: int | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Generate testing data for the multi_mediators case study.\n",
    "\n",
    "    :param num_samples: The number of samples to generate. Try 1000.\n",
    "    :param treatments: An optional dictionary of the values to fix each variable to.\n",
    "    :param seed: An optional random seed for reproducibility purposes\n",
    "    :returns: A pandas Dataframe with columns corresponding\n",
    "        to the variable names in the multi_mediators example\n",
    "    \"\"\"\n",
    "    if treatments is None:\n",
    "        treatments = {}\n",
    "    generator = np.random.default_rng(seed)\n",
    "\n",
    "    # latent confounder between x and y\n",
    "    u = generator.normal(loc=50.0, scale=10.0, size=num_samples)\n",
    "\n",
    "    # latent confounder between m1 and y\n",
    "    u2 = generator.normal(loc=40.0, scale=10.0, size=num_samples)\n",
    "\n",
    "    beta0_x = 1\n",
    "    beta_u_to_x = 0.7\n",
    "\n",
    "    if X in treatments:\n",
    "        x = np.full(num_samples, treatments[X])\n",
    "    else:\n",
    "        loc_x = beta0_x + u * beta_u_to_x\n",
    "        x = generator.normal(loc=loc_x, scale=10.0, size=num_samples)\n",
    "\n",
    "    beta0_m1 = 2\n",
    "    beta_x_to_m1 = 0.7\n",
    "    beta_u2_to_m1 = 0.8\n",
    "\n",
    "    if M1 in treatments:\n",
    "        m1 = np.full(num_samples, treatments[M1])\n",
    "    else:\n",
    "        loc_m1 = beta0_m1 + x * beta_x_to_m1 + u2 * beta_u2_to_m1\n",
    "        m1 = generator.normal(loc=loc_m1, scale=10.0, size=num_samples)\n",
    "\n",
    "    beta0_m2 = 2\n",
    "    beta_m1_to_m2 = 0.7\n",
    "\n",
    "    if M2 in treatments:\n",
    "        m2 = np.full(num_samples, treatments[M2])\n",
    "    else:\n",
    "        loc_m2 = beta0_m2 + m1 * beta_m1_to_m2\n",
    "        m2 = generator.normal(loc=loc_m2, scale=10.0, size=num_samples)\n",
    "\n",
    "    beta0_y = 1.8\n",
    "    beta_u_to_y = 0.5\n",
    "    beta_u2_to_y = 0.7\n",
    "    beta_m2_to_y = 0.7\n",
    "    if Y in treatments:\n",
    "        y = np.full(num_samples, treatments[Y])\n",
    "    else:\n",
    "        y = generator.normal(\n",
    "            loc=beta0_y + u * beta_u_to_y + m2 * beta_m2_to_y + u2 * beta_u2_to_y,\n",
    "            scale=10.0,\n",
    "            size=num_samples,\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame({X.name: x, M1.name: m1, M2.name: m2, Y.name: y})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T15:33:47.750063Z",
     "start_time": "2023-11-08T15:33:46.282241Z"
    }
   },
   "id": "8f0aab553754884c"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             X         M1         M2           Y\n",
      "0    18.992610  49.883194  56.573267   85.846859\n",
      "1    49.125191  87.267363  57.150454   97.293062\n",
      "2    25.945798  76.534566  53.086703   95.511387\n",
      "3    32.727188  51.363763  27.622896   90.255422\n",
      "4    19.540822  53.806707  47.854845   77.755610\n",
      "..         ...        ...        ...         ...\n",
      "495  59.823829  85.712292  53.319056   91.729554\n",
      "496  58.325722  71.227536  38.329188   89.349353\n",
      "497  39.625217  64.373556  42.604040   79.603049\n",
      "498  22.381303  64.399794  52.821084  113.413001\n",
      "499  49.178552  65.879525  44.897816  101.672669\n",
      "\n",
      "[500 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#get data\n",
    "data = generate(500)\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T15:34:04.572197Z",
     "start_time": "2023-11-08T15:34:03.246707Z"
    }
   },
   "id": "992041bf02ca4cb5"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "Total number of conditional independencies: 2\n",
      "Total number of failed tests: 0\n",
      "Percentage of failed tests: 0.00%\n",
      "left right given  p-value result\n",
      "  M2     X    M1      NaN   pass\n",
      "  M1     Y  M2|X      NaN   pass\n"
     ]
    }
   ],
   "source": [
    "conditional_independence_test_summary(graph, data, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T14:05:49.840299Z",
     "start_time": "2023-11-08T14:05:44.097052Z"
    }
   },
   "id": "ac050daeb0ad1c27"
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see it produces NaN for the p-value."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d424dbcc64d6b8db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Example 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8f086b3cf032944"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from y0.algorithm.identify import Query\n",
    "from y0.dsl import Z1, Z2, Z3, Variable, X, Y\n",
    "from y0.examples import Example\n",
    "from y0.graph import NxMixedGraph\n",
    "\n",
    "M1 = Variable(\"M1\")\n",
    "M2 = Variable(\"M2\")\n",
    "R1 = Variable(\"R1\")\n",
    "R2 = Variable(\"R2\")\n",
    "R3 = Variable(\"R3\")\n",
    "\n",
    "\n",
    "graph = NxMixedGraph.from_edges(\n",
    "    directed=[\n",
    "        (Z1, X),\n",
    "        (X, M1),\n",
    "        (M1, M2),\n",
    "        (M2, Y),\n",
    "        (Z1, Z2),\n",
    "        (Z2, Z3),\n",
    "        (Z3, Y),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "def generate(\n",
    "    num_samples: int = 1000,\n",
    "    treatments: dict[Variable, float] | None = None,\n",
    "    *,\n",
    "    seed: int | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Generate testing data for the multi_mediators_confounder case study.\n",
    "\n",
    "    :param num_samples: The number of samples to generate. Try 1000.\n",
    "    :param treatments: An optional dictionary of the values to fix each variable to.\n",
    "    :param seed: An optional random seed for reproducibility purposes\n",
    "    :returns: A pandas Dataframe with columns corresponding\n",
    "        to the variable names in the multi_mediators_confounder example\n",
    "    \"\"\"\n",
    "    if treatments is None:\n",
    "        treatments = {}\n",
    "    generator = np.random.default_rng(seed)\n",
    "\n",
    "    # latent node between X and Z1\n",
    "    # u1 = generator.normal(loc=40.0, scale=10.0, size=num_samples)\n",
    "    # latent node between Y and Z2\n",
    "    u2 = generator.normal(loc=50.0, scale=10.0, size=num_samples)\n",
    "\n",
    "    beta0_z1 = 50  # 1.5\n",
    "    # beta_u1_to_z1 = 0.3\n",
    "\n",
    "    if Z1 in treatments:\n",
    "        z1 = np.full(num_samples, treatments[Z1])\n",
    "    else:\n",
    "        loc_z1 = beta0_z1  # + u1 * beta_u1_to_z1\n",
    "        z1 = generator.normal(loc=loc_z1, scale=10.0, size=num_samples)\n",
    "\n",
    "    beta0_z2 = 3\n",
    "    beta_z1_to_z2 = 0.3\n",
    "    beta_u2_to_z2 = 0.7\n",
    "\n",
    "    if Z2 in treatments:\n",
    "        z2 = np.full(num_samples, treatments[Z2])\n",
    "    else:\n",
    "        loc_z2 = beta0_z2 + z1 * beta_z1_to_z2 + u2 * beta_u2_to_z2\n",
    "        z2 = generator.normal(loc=loc_z2, scale=4.0, size=num_samples)\n",
    "\n",
    "    beta0_z3 = 4\n",
    "    beta_z2_to_z3 = 0.6\n",
    "\n",
    "    if Z3 in treatments:\n",
    "        z3 = np.full(num_samples, treatments[Z3])\n",
    "    else:\n",
    "        loc_z3 = beta0_z3 + z2 * beta_z2_to_z3\n",
    "        z3 = generator.normal(loc=loc_z3, scale=4.0, size=num_samples)\n",
    "\n",
    "    beta0_x = 1\n",
    "    beta_z1_to_x = 0.6\n",
    "    # beta_u1_to_x = 0.3\n",
    "\n",
    "    if X in treatments:\n",
    "        x = np.full(num_samples, treatments[X])\n",
    "    else:\n",
    "        loc_x = beta0_x + z1 * beta_z1_to_x  # + u1 * beta_u1_to_x\n",
    "        x = generator.normal(loc=loc_x, scale=4.0, size=num_samples)\n",
    "\n",
    "    beta0_m1 = 2\n",
    "    beta_x_to_m1 = 0.7\n",
    "\n",
    "    if M1 in treatments:\n",
    "        m1 = np.full(num_samples, treatments[M1])\n",
    "    else:\n",
    "        loc_m1 = beta0_m1 + x * beta_x_to_m1\n",
    "        m1 = generator.normal(loc=loc_m1, scale=4.0, size=num_samples)\n",
    "\n",
    "    beta0_m2 = 2\n",
    "    beta_m1_to_m2 = 0.7\n",
    "\n",
    "    if M2 in treatments:\n",
    "        m2 = np.full(num_samples, treatments[M2])\n",
    "    else:\n",
    "        loc_m2 = beta0_m2 + m1 * beta_m1_to_m2\n",
    "        m2 = generator.normal(loc=loc_m2, scale=7.0, size=num_samples)\n",
    "\n",
    "    beta0_y = 1.8\n",
    "    beta_z3_to_y = 0.5\n",
    "    beta_m2_to_y = 0.7\n",
    "    beta_u2_to_y = 0.8\n",
    "    if Y in treatments:\n",
    "        y = np.full(num_samples, treatments[Y])\n",
    "    else:\n",
    "        loc_y = beta0_y + z3 * beta_z3_to_y + m2 * beta_m2_to_y + u2 * beta_u2_to_y\n",
    "        y = generator.normal(\n",
    "            loc=loc_y,\n",
    "            scale=10.0,\n",
    "            size=num_samples,\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            X.name: x,\n",
    "            M1.name: m1,\n",
    "            M2.name: m2,\n",
    "            Z1.name: z1,\n",
    "            Z2.name: z2,\n",
    "            Z3.name: z3,\n",
    "            Y.name: y,\n",
    "        }\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T14:01:25.096518Z",
     "start_time": "2023-11-08T14:01:24.849481Z"
    }
   },
   "id": "59f9fa1ffd35970e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "data = generate(500)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T14:01:25.792197Z",
     "start_time": "2023-11-08T14:01:25.687766Z"
    }
   },
   "id": "96ff5debacbeb717"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "/Users/sarataheri/GitHub/eliater/venv/lib/python3.11/site-packages/pgmpy/estimators/CITests.py:548: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for z_state, df in data.groupby(Z):\n",
      "Total number of conditional independencies: 14\n",
      "Total number of failed tests: 0\n",
      "Percentage of failed tests: 0.00%\n",
      "left right given  p-value result\n",
      "  M2    Z2    M1      NaN   pass\n",
      "  M1     Y M2|Z2      NaN   pass\n",
      "   Y    Z1 M1|Z2      NaN   pass\n",
      "   X    Z3    Z2      NaN   pass\n",
      "  Z1    Z3    Z2      NaN   pass\n",
      "  M2    Z3    Z2      NaN   pass\n",
      "   Y    Z2 M1|Z3      NaN   pass\n",
      "  M1    Z3    Z2      NaN   pass\n",
      "   X    Z2    Z1      NaN   pass\n",
      "  M2     X    M1      NaN   pass\n",
      "  M2    Z1    M1      NaN   pass\n",
      "   X     Y M1|Z2      NaN   pass\n",
      "  M1    Z1     X      NaN   pass\n",
      "  M1    Z2    Z1      NaN   pass\n"
     ]
    }
   ],
   "source": [
    "conditional_independence_test_summary(graph, data, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T14:02:22.905556Z",
     "start_time": "2023-11-08T14:01:52.004637Z"
    }
   },
   "id": "fe56e14bcef6eb40"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "79a96fffe9741faf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
